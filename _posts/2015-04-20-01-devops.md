---
layout:     post
title:      "1.5 Setting up a local environment to mimic production"
subtitle:   "Setting up working environments with the magic of DevOps."
date:       2015-04-20 12:00:00
author:     "Dcycle"
header-img: "img/post-bg-01.jpg"
class:      "1"
parent:     "<a href=\"/class-01-basics\">Class 1: Basics</a>"
---

The challenge of local development
-----

Recall the challenges posed by local development:

 * Keeping track of different versions of the same project.
 * **Making sure the project behaves the same way on each environment.**

We had a glimpse of the first challenge in the previous lesson, as we looked at using Git. We'll look more into Git in a future lesson.

The second challenge has long haunted the development community, but a solution is in sight, and we'll start using it in this lesson.

Different types of websites
-----

OK, _I know_ that you know how a website works, but bear with me: your browser sends a request to a server, and in return gets **html**, **css**, and **javascript** files. Together, these make up what is displayed to you.

There are **three main ways** to deliver these files:

 * **Option one**: The first is to write them directly to text files yourself, and then save them to a webserver, or even to your desktop. Sites built in this way can be viewed directly on your computer without any special software, by opening them in your browser directly. Non-trivial sites are never built this way because the technique is error-prone and not very powerful.

 * **Option two**: You can also write your sites in languages other than, or in addition to, html, css, and javascript. These sites need to be **built**, that is, transformed into files your browser understands; the resulting files can then be viewed in your browser. This is the technique we've used in the blog we created in the first lesson: it uses a technology called [Jekyll](http://jekyllrb.com) to take files which your browser does not understand, and _transform them_ into files it does. These files are not built every time you visit a page; rather, they are built at a set interval. For example, GitHub builds your site every time it detects a change to the underlying code (changing a site's title, for instance).

For example, Jekyll takes `yml` files such as `_config.yml` which contain information like:

    title: Clean Blog
    description: "A Clean Blog Theme by Start Bootstrap"


Every time a change is made to a file such as the above, Jekyll can transform that information into HTML like:

    <div class="site-heading">
        <h1>Clean Blog</h1>
        <hr class="small">
        <span class="subheading">A Clean Blog Theme by Start Bootstrap</span>
    </div>

Don't worry if you don't fully understand how HTML works; the important thing is: your browser understands it, and can display it.

 * **Option three**: The third option, used by Drupal, which is written in PHP, interprets source code every time a request is made, and uses software to build HTML on the fly.

For example, a PHP file like:

    <?php
    $rand = rand();
    print ('<h1>This is a random number: ' . $rand . '</h1>');
    ?>

Will be interpreted as:

    <h1>This is a random number: 83748</h1>

The next time you load your page, you might see:

    <h1>This is a random number: 38292</h1>

In all cases, your browser sees _html_, or other formats it understands, and **does not care about underlying technology**.

If you are using option two or three, your site will be not be visible on your computer because you don't have the required software to translate it into html (PHP, webservers, Jekyll, etc.). Creating a local environment requires that software.

Three approaches to creating a local environment
-----

Assuming you are not modifying code directly on the production environment, here are three approaches to local development:

 * **The worst thing you can do is try to install that software directly on your local computer**! If you are developing a PHP application like Drupal, software packages like MAMP and XAMPP might work at first, but you will soon run into software mismatches, which can eat up days or weeks of your time. You do not want to deal with permissions issues, software version mismatches, and other weird issues. If you want to build your Jekyll site, you might try to install Jekyll on your Mac, for example, and it might work, but your colleague who has Windows might hit a wall. There has to be a better way! And there is...

 * The next approach is to use virtual machines. So: if you are not installing software on your laptop, perhaps you can create virtual machines which contain the required software. We already know how to use Vagrant, we've used it to set up a virtual machine which runs the CoreOS operating system. Let's say your website is designed to use the Ubuntu operating system; now that you know how to use Vagrant, you can set a VM with Ubuntu. What about the software? You might have heard of configuration management tool such as Puppet, Chef, or Ansible that define what should be on your machine: For example, PHP 5.3, Apache, MySQL are required to run Drupal. To be honest, **I do not recommend this** because virtual machines are expensive. We already have a CoreOS VM, and we don't want to bog our computer down with a bunch of virtual machines, one for each project we're working on.

 * **My personal favorite, _containers_**: what if we could have the benefit of virtual machines, but with the speed of a local machine, all without having to bother with learning Puppet, Chef, or Ansible. **Containers** do exactly that. What's wrong with VMs? VMs replicate a complete operating system (OS) as a guest, living on a host. So: a lot of what makes your OS work and take up resources _is replicated_ on each virtual machine. This is inefficient. Containers, on the other hand, share resources with the host, which makes them much more nimble.

Remember how Vagrant is a command-line tool to easily manage VMs? Well, it turns out there is a tool which does the same thing but for containers: [Docker](https://www.docker.com). Not only is Docker easy to use to manage containers, it uses caching very well. This means that when you build a container a first time time, it can take a while (still shorter than building a VM); when you build it a second time, it takes _about one second_.

If you are still confused, or want to learn more about containers vs. VMs, I highly recommend the article [Getting Started with Docker, on Servers for Hackers (March 20, 2014)](https://serversforhackers.com/getting-started-with-docker).

OK, so if containers are the best thing since sliced bread, then why did we install CoreOS as Virtual Machine, rather than a container? Containers rely on an underlying technology which is not available on Mac OS or Windows. The basic premise of CoreOS is to make an operating system as small and efficient as possible, include necessary software, and **work with containers**. That's why we installed CoreOS: so we all have the same starting point to run containers via Docker.

Exercise: setting up a local version of the site you're on right now
-----

Dcycle U. is an open-source site; you can copy its structure and content, and do what you want with it, as long as you mention its source and don't claim it as your own.

Go to the [Dcycle U. code page on GitHub](https://github.com/dcycleproject/dcycleu) and locate the _clone URL_:

<img src="/img/2015-04-20-01-clone-dcycleu.png" />

Note that because you don't the permission to modify the Dcycle U. code directly (although you can fork it if you want), you don't see the SSH clone method, as you do for your own projects. Keep the HTTPS method, which is fine for our purposes. The difference is that you don't need an SSH key to use it, and you won't be able to push changes from your computer to GitHub.

Now go to your CoreOS machine, and clone Dcycle U:

    core@core-01 ~ $ cd share
    core@core-01 ~/share $ git clone https://github.com/dcycleproject/dcycleu.git
    Cloning into 'dcycleu'...
    remote: Counting objects: 163, done.
    remote: Total 163 (delta 0), reused 0 (delta 0), pack-reused 163
    Receiving objects: 100% (163/163), 5.46 MiB | 1.25 MiB/s, done.
    Resolving deltas: 100% (40/40), done.
    Checking connectivity... done.
    core@core-01 ~/share $ cd dcycleu
    core@core-01 ~/share/dcycleu $

Understanding the files
-----

Dcycle U. has a few files which are required to set up a local environment. The first is `Dockerfile-dev`, and contains:

    from nginx

    # install Jekyll
    RUN apt-get update
    # build-essential includes make which is required to install jekyll
    RUN apt-get install build-essential -y
    # install ruby so we can install jekyll on top of it.
    RUN apt-get install ruby1.9.1-dev -y
    # V is verbose, just to reassure folks that this takes times
    RUN gem install jekyll -V
    # see https://github.com/jekyll/jekyll/issues/2327
    RUN gem install execjs
    RUN gem install therubyracer

    RUN mkdir -p /usr/share/site/_site
    RUN rm -rf /usr/share/nginx/html/
    RUN ln -s ../site/_site /usr/share/nginx/html

    expose 80

**Don't worry if you don't understand every line**. The important thing is that this file contains everything needed to set up a server for Jekyll: it starts with a standard machine with Nginx (Nginx is software which allows you to serve html files to a web browser), and adds Jekyll, as well as some other software Jekyll requires. With this recipe, Docker will be able to completely create a Jekyll-ready webserver in a container---and destroy it when it is done with it.

The second file is `scripts/build-dev.sh`, which contains:

    docker build -f="Dockerfile-dev" -t docker-dcycleu-dev .
    docker run -d -p 80:80 -v $(pwd):/usr/share/site/ docker-dcycleu-dev

This is a script file, and it contains a series of commands. Typing the name of this script is the equivalent of typing its contents in the command line.

Before running it, let's take a look at what it says:

 * Use `docker`, the tool we use to manage containers and which is included in CoreOS, to build a new _image_ based on the file `Dockerfile-dev`, which we've seen above. Call our image `docker-dcycleu-dev`. Think of an image as a hard disk which is not plugged into a computer.
 * Once we have our image, create a new container with it. Think of a container as a running computer with which we can interact. `-p 80:80` makes sure that we can access our  container using port 80. Port 80 is the port used by web browsers; if port 80 is not accessible, web browsers will not be able to fetch web pages from a server. `-v $(pwd):/usr/share/site/` tells our container to share all the files which are in the current directory on the CoreOS virtual machine, and reserve the path `/usr/share/site/` on the container for those files.

Let's recap how files are shared. In lesson 1.3. we put our vagrant machine at `~/Documents/coreos-vagrant` on our laptop.

 * `~/Documents/coreos-vagrant/dcycleu/README.md` on our laptop _is the same file_ as `~/share/dcycleu/README.md` on our CoreOS VM.
 * Once we have a running container, `~/share/dcycleu/README.md` _will be the same file_ as `~/Documents/coreos-vagrant/dcycleu/README.md` on our laptop, which _will be the same file_ as `/usr/share/site/README.md` on the container, which itself is running on top of CoreOS.
 * The files are actually the same, _they are not copies, but the same file_: Changes to README.md in one place will change the file on all three locations.

Running a local environment
-----

Start by checking which containers are currently running by using the `docker ps` command.

    core@core-01 ~ $ docker ps
    CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
    core@core-01 ~ $

That's normal: you have no running containers yet. Time to run the script!

    core@core-01 ~ $ cd ~/share/dcycleu/
    core@core-01 ~/share/dcycleu $ ./scripts/build-dev.sh

Depending on your internet speed, this might take a while the first time you run it.
When it's done, check your running containers again. You should have one.

    core@core-01 ~/share/dcycleu $ docker ps
    CONTAINER ID        IMAGE                       COMMAND                CREATED             STATUS              PORTS                         NAMES
    5f08fe759cf8        docker-dcycleu-dev:latest   "nginx -g 'daemon of   27 seconds ago      Up 27 seconds       0.0.0.0:80->80/tcp, 443/tcp   furious_nobel

Because your container is accessible on port 80 (the port that websites use), you will be able to open a browser on your computer, and visit `http://172.17.8.101` (that's the internal IP address of your CoreOS VM).

Are you seeing the DcycleU website? Great! If not, file an issue.

OK, time to see one of the main advantages of containers: speed. Start by killing the container. This will not touch your code, it just kills the container where it is being run. First, find the ID of your running container. In this example, it's `5f08fe759cf8`. Then kill it with:

    core@core-01 ~/share/dcycleu $ docker kill 5f08fe759cf8

You can also use `5f0` instead of `5f08fe759cf8` if you don't like copy-pasting. If you visit `http://172.17.8.101` or run `docker ps` now, you won't see that container anymore. Try building the container again and count how long it takes:

    core@core-01 ~/share/dcycleu $ ./scripts/build-dev.sh

About one second, right? Keep in mind that we are doing the equivalent of starting up a server, booting an operating system, and starting all relevant software. That's the speed of Docker.

Make a change to Dcycle U.
-----

On your computer now, find Dcycle U.'s `_config.yml` file, make a change to the site's title using your text editor, and save it.

As of this writing, I have not managed to get the container to automatically update the site every time you make a local change. There is an outstanding issue about that, called [Make Jekyll site regenerate automatically inside Docker container](https://github.com/dcycleproject/dcycleu/issues/5), if you are interested.

So, until that issue is resolved, you will need to run the following command to update the local site:

    core@core-01 ~/share/dcycleu $ ./scripts/jekyll-build.sh

Exercise: changing your own site locally
-----

OK, now that you have made to the Dcycle U. site, you can delete that folder.

Also, make sure you kill the Dcycle U. container, or else no other container will be able to exist on port 80, and you will get the error `Cannot start container ...: Bind for 0.0.0.0:80 failed: port is already allocated`.

Recall the three files within the Dcycle U. that allowed us to create a container and update our site:

 * `Dockerfile-dev`.
 * `scripts/build-dev.sh`.
 * `scripts/jekyll-build.sh`.

You can create those three files in your own project now (make sure to put them in the right place; `Docker-dev` should be in your project root; and scripts should be in a folder called `scripts`). In `scripts/build-dev.sh`, make sure you change the two instances of `docker-dcycleu-dev` to a custom ID for your own project, like `docker-johns-flower-blog-dev`.

 * Navigate into your folder using `cd ~/startbootstrap-clean-blog-jekyll-gh-pages`, on the CoreOS VM.
 * Run `scripts/build-dev.sh`.
 * Make any changes you want directly on your computer.
 * Run `scripts/jekyll-build.sh`.

Exercise: push your changes live
-----

If all went well, your local environment at `http://172.17.8.101` should contain your changes, but not the site as it is hosted for the public on GitHub.

Changes are pushed via Git. Because we **added files** to our Git repo (`scripts/build-dev.sh` and `scripts/jekyll-build.sh`), we need to _add them_ before committing, using Git's `add` command. Here's is what to do:

    core@core-01 ~/share/startbootstrap-clean-blog-jekyll-gh-pages $ git add scripts
    core@core-01 ~/share/startbootstrap-clean-blog-jekyll-gh-pages $ git commit -am 'Added Docker support'
    core@core-01 ~/share/startbootstrap-clean-blog-jekyll-gh-pages $ git push origin master

If you add files to your local repo, Git will ignore them until they are added with `git add`. To see if Git is ignoring anything you can type `git status`.

After less than a minute, the changes you made locally should appear on your live, or production, site---the one hosted on GitHub.

Recap
-----

It is useful to take a minute and understand all we have accomplished, as this solid base will prevent countless headaches in the future:

 * All our changes can now be under **version control**. This prevents confusion about what is the most up-to-date version of our code.
 * We are using a **Dev-Production workflow** (later on, we'll use dev-stage-production). This allows not just you, but anyone to whom you give access, to make local modifications on their computer, and push them live.
 * We are using a **DevOps** workflow. This allows anyone on any computer on any OS to start developing right away. All that is needed is Vagrant, VirtualBox and CoreOS VM. If you have worked on teams which did things before DevOps, you know the colossal amount of time you will be saving by not having to debug Tom's development environment because he does not have PHP mb_string extension installed, or Sylvia's environment because she does not have the permission to `chmod` _sites to 755, your own instance of Jekyll because you just upgraded Mac OS and it broke everything, **and innumerable other things you don't care about**.

Before moving on:
-----

Before looking at the next lesson, you should now be familiar with:

 * Adding files to git using `git add`.
 * How to list Docker containers running on your CoreOS VM.
 * How to kill a Docker container.
 * What people mean when they say DevOps: embedding the server information with the project code to be able to create and maintain standardized environments.
 * Two DevOps tools, what they do, and how they differ: [Vagrant](https://www.vagrantup.com), and [Docker](https://www.docker.com).

